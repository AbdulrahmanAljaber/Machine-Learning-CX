{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57a37bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "fc8af3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Package imports\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import sklearn.linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "70fe0c9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3048</td>\n",
       "      <td>71.3</td>\n",
       "      <td>0.002663</td>\n",
       "      <td>126.201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3048</td>\n",
       "      <td>71.3</td>\n",
       "      <td>0.002663</td>\n",
       "      <td>125.201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3048</td>\n",
       "      <td>71.3</td>\n",
       "      <td>0.002663</td>\n",
       "      <td>125.951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3048</td>\n",
       "      <td>71.3</td>\n",
       "      <td>0.002663</td>\n",
       "      <td>127.591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3048</td>\n",
       "      <td>71.3</td>\n",
       "      <td>0.002663</td>\n",
       "      <td>127.461</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0    1       2     3         4        5\n",
       "0   800  0.0  0.3048  71.3  0.002663  126.201\n",
       "1  1000  0.0  0.3048  71.3  0.002663  125.201\n",
       "2  1250  0.0  0.3048  71.3  0.002663  125.951\n",
       "3  1600  0.0  0.3048  71.3  0.002663  127.591\n",
       "4  2000  0.0  0.3048  71.3  0.002663  127.461"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Airfoil.csv',header = None)\n",
    "print(df.isnull().values.any())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "f794aad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df[5].values.reshape(-1,1)\n",
    "X = df.drop([5],axis =1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "464fa390",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler().fit(X)\n",
    "X = scaler.transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "2a9fc1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data, train_labels, test_labels = train_test_split(X,Y,test_size=0.30,random_state=777)\n",
    "val_data, test_data, val_labels, test_labels = train_test_split(test_data,test_labels ,test_size=0.50,random_state=777)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "d941383c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = train_labels.reshape(len(train_labels),1)\n",
    "test_labels = test_labels.reshape(len(test_labels),1)\n",
    "val_labels = val_labels.reshape(len(val_labels),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "458a82fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainx = train_data.T\n",
    "trainy = train_labels.T\n",
    "\n",
    "valx = val_data.T\n",
    "valy = val_labels.T\n",
    "\n",
    "testx = test_data.T\n",
    "testy =test_labels.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "b61f6123",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=trainx\n",
    "Y=trainy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "2d45222e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of training samples: 1052\n",
      "Number of features per sample: 5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "### START CODE HERE ###\n",
    "shape_X = trainx.shape\n",
    "shape_Y = trainy.shape\n",
    "m = trainx.shape[1]  # training set size\n",
    "### END CODE HERE ###\n",
    "\n",
    "print ('No. of training samples: ' + str(m))\n",
    "print ('Number of features per sample: ' + str(shape_X[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "bf61502b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5, 1052), (1, 1052), (5, 225), (1, 225), (5, 226), (1, 226))"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainx.shape, trainy.shape, valx.shape, valy.shape, testx.shape, testy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "f488c022",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_architecture(X, Y):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    X -- input dataset of shape (input size, number of examples)\n",
    "    Y -- labels of shape (output size, number of examples)\n",
    "    \n",
    "    Returns:\n",
    "    n_x -- the size of the input layer\n",
    "    n_h -- the size of the hidden layer\n",
    "    n_y -- the size of the output layer\n",
    "    \"\"\"\n",
    "    ### START CODE HERE ### \n",
    "    n_x = X.shape[0] # size of input layer\n",
    "    n_h = 10\n",
    "    n_y = Y.shape[0] # size of output layer\n",
    "    ### END CODE HERE ###\n",
    "    return (n_x, n_h, n_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "39e72952",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(n_x, n_h, n_y):\n",
    "    \"\"\"\n",
    "    Argument:\n",
    "    n_x -- size of the input layer\n",
    "    n_h -- size of the hidden layer\n",
    "    n_y -- size of the output layer\n",
    "    \n",
    "    Returns:\n",
    "    params -- python dictionary containing your parameters:\n",
    "                    W1 -- weight matrix of shape (n_h, n_x)\n",
    "                    b1 -- bias vector of shape (n_h, 1)\n",
    "                    W2 -- weight matrix of shape (n_y, n_h)\n",
    "                    b2 -- bias vector of shape (n_y, 1)\n",
    "    \"\"\"\n",
    "    \n",
    "    np.random.seed(2)\n",
    "\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    W1 = np.random.randn(n_h,n_x)*0.01\n",
    "    b1 = np.zeros((n_h,1))\n",
    "    W2 = np.random.randn(n_y,n_h)*0.01\n",
    "    b2 = np.zeros((n_y,1))\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    assert (W1.shape == (n_h, n_x))\n",
    "    assert (b1.shape == (n_h, 1))\n",
    "    assert (W2.shape == (n_y, n_h))\n",
    "    assert (b2.shape == (n_y, 1))\n",
    "    \n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2}\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "6595ea65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(X, parameters):\n",
    "    \n",
    "    # Retrieve each parameter from the dictionary \"parameters\"\n",
    "    ### START CODE HERE ### \n",
    "    W1 = parameters[\"W1\"]\n",
    "    b1 = parameters[\"b1\"]\n",
    "    W2 = parameters[\"W2\"]\n",
    "    b2 = parameters[\"b2\"]\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Implement Forward Propagation to calculate A2 (probabilities)\n",
    "    ### START CODE HERE ### \n",
    "    Z1 = np.dot(W1 , X) + b1\n",
    "    A1 = np.tanh(Z1)\n",
    "    Z2 = np.dot(W2 , A1) + b2\n",
    "    A2 = Z2\n",
    "    \n",
    "\n",
    "    \n",
    "    cache = {\"Z1\": Z1,\n",
    "             \"A1\": A1,\n",
    "             \"Z2\": Z2,\n",
    "             \"A2\": A2}\n",
    "    \n",
    "    return A2, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "5e71d03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(A2, Y):\n",
    "   \n",
    "    m = Y.shape[1] # number of example\n",
    "    \n",
    "    \n",
    "    cost = -(1/m)*np.sum(np.multiply(Y,np.log(A2)))\n",
    "    loss= np.sum(cost)/(100*m)\n",
    "    \n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "42376f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backprop(parameters, cache, X, Y):\n",
    "\n",
    "    m = X.shape[1]\n",
    "    \n",
    "    # First, retrieve W1 and W2 from the dictionary \"parameters\".\n",
    "    ### START CODE HERE ### \n",
    "    W1 = parameters[\"W1\"]\n",
    "    b1 = parameters[\"b1\"]\n",
    "    W2 = parameters[\"W2\"]\n",
    "    b2 = parameters[\"b2\"]\n",
    "    ### END CODE HERE ###\n",
    "        \n",
    "    # Retrieve also A1 and A2 from dictionary \"cache\".\n",
    "    ### START CODE HERE ### \n",
    "    A1 = cache[\"A1\"]\n",
    "    A2 = cache[\"A2\"]\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Backward propagation: calculate dW1, db1, dW2, db2. \n",
    "    ### START CODE HERE ### \n",
    "    dZ2 = A2 - Y\n",
    "    dW2 = (1/m)*np.dot(dZ2,A1.T)\n",
    "    db2 = (1/m)*np.sum(dZ2)\n",
    "    dZ1 = np.multiply(np.dot(W2.T,dZ2), 1-np.power(A1,2))\n",
    "    dW1 = (1/m)*np.dot(dZ1,X.T)\n",
    "    db1 = (1/m)*np.sum(dZ1)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    grads = {\"dW1\": dW1,\n",
    "             \"db1\": db1,\n",
    "             \"dW2\": dW2,\n",
    "             \"db2\": db2}\n",
    "    \n",
    "    return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "1e3d47d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update(parameters, grads, learning_rate = 0.01):\n",
    "\n",
    "    # Retrieve each parameter from the dictionary \"parameters\"\n",
    "    ### START CODE HERE ### \n",
    "    W1 = parameters[\"W1\"]\n",
    "    b1 = parameters[\"b1\"]\n",
    "    W2 = parameters[\"W2\"]\n",
    "    b2 = parameters[\"b2\"]\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Retrieve each gradient from the dictionary \"grads\"\n",
    "    ### START CODE HERE ### \n",
    "    dW1 = grads[\"dW1\"]\n",
    "    db1 = grads[\"db1\"]\n",
    "    dW2 = grads[\"dW2\"]\n",
    "    db2 = grads[\"db2\"]\n",
    "    ## END CODE HERE ###\n",
    "    \n",
    "    # Update rule for each parameter\n",
    "    ### START CODE HERE ### \n",
    "    W1 = W1 - learning_rate*dW1\n",
    "    b1 = b1 - learning_rate*db1\n",
    "    W2 = W2 - learning_rate*dW2\n",
    "    b2 = b2 - learning_rate*db2\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2}\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "4ad089dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(parameters, X):\n",
    "\n",
    "    ### START CODE HERE ### 1\n",
    "    A2, cache = forward_propagation(X, parameters)\n",
    "\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return A2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "4a7e938d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NeuralNetwork(X, Y, n_h, num_iterations = 10000, learning_rate = 0.01, print_loss=False):\n",
    "\n",
    "    np.random.seed(3)\n",
    "    n_x = model_architecture(X, Y)[0]\n",
    "    n_y = model_architecture(X, Y)[2]\n",
    "    \n",
    "    # Initialize parameters\n",
    "    ### START CODE HERE ### \n",
    "    parameters = initialize_parameters(n_x, n_h, n_y)\n",
    "    W1 = parameters[\"W1\"]\n",
    "    b1 = parameters[\"b1\"]\n",
    "    W2 = parameters[\"W2\"]\n",
    "    b2 = parameters[\"b2\"]\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Loop (gradient descent)\n",
    "\n",
    "    for i in range(0, num_iterations):\n",
    "         \n",
    "        ### START CODE HERE ### \n",
    "        # Forward propagation. Inputs: \"X, parameters\". Outputs: \"A2, cache\".\n",
    "        A2, cache = forward_propagation(X, parameters)\n",
    "        \n",
    "        # loss function. Inputs: \"A2, Y, parameters\". Outputs: \"loss\".\n",
    "        loss = compute_loss(A2, Y)\n",
    " \n",
    "        # Backpropagation. Inputs: \"parameters, cache, X, Y\". Outputs: \"grads\".\n",
    "        grads = backprop(parameters, cache, X, Y)\n",
    " \n",
    "        # Gradient descent parameter update. Inputs: \"parameters, grads\". Outputs: \"parameters\".\n",
    "        parameters =  update(parameters, grads, learning_rate = 0.01)\n",
    "        \n",
    "        ### END CODE HERE ###\n",
    "        \n",
    "        # Print the loss every 100 iterations\n",
    "        if print_loss and i % 100 == 0:\n",
    "            \n",
    "            print (\"loss after iteration %i: %f\" %(i, loss))\n",
    "\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "fe4129af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\0xboja\\AppData\\Local\\Temp/ipykernel_23256/3295651497.py:6: RuntimeWarning: invalid value encountered in log\n",
      "  cost = -(1/m)*np.sum(np.multiply(Y,np.log(A2)))\n"
     ]
    }
   ],
   "source": [
    "# Build a model with a n_h-dimensional hidden layer\n",
    "parameters = NeuralNetwork(X, Y, n_h = 1000, num_iterations = 100, learning_rate = 0.1, print_loss=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "b3c1ba78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE =  1.2898972172355974e+191\n"
     ]
    }
   ],
   "source": [
    "#MSE\n",
    "\n",
    "pred = predict(parameters, trainx)\n",
    "MSE = np.square(np.subtract(trainy,pred)).mean()\n",
    "print(\"MSE = \" , MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "b02e862f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE =  2.8866954679560465e+93\n"
     ]
    }
   ],
   "source": [
    "MAE = np.mean(np.abs(np.subtract(trainy,pred)/trainy))\n",
    "print('MAE = ', MAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff5d0df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
